# Computer Vision and Generative Models

This repository contains a collection of tutorials and resources for learning about various aspects of computer vision and generative models using PyTorch. Each folder contains code and explanations for a specific topic.

## Table of Contents

1. [Intro to Torch](#1-intro-to-torch)
2. [Network Visualization](#2-network-visualization)
3. [CNNs Saliencies](#3-cnns-saliencies)
4. [DeepDream](#4-deepdream)
5. [AutoEncoders](#5-autoencoders)
6. [GANs](#6-gans)
7. [RNNs and LSTMs](#7-rnns-and-lstms)
8. [Vision Transformers](#8-vision-transformers)

## 1. Intro to Torch

This section provides an introduction to PyTorch, covering basic concepts and functionalities. You will learn how to:
- Install and set up PyTorch.
- Work with tensors.
- Build and train a simple neural network.

## 2. Network Visualization

In this section, you will explore different techniques for visualizing neural networks, including:
- Visualizing the architecture of neural networks.
- Plotting the computational graph.
- Understanding the flow of data through the network.

## 3. CNNs Saliencies

This section covers the concept of saliency maps in Convolutional Neural Networks (CNNs). You will learn how to:
- Generate saliency maps to understand which parts of an image contribute most to the predictions.
- Implement Grad-CAM and other visualization techniques.

## 4. DeepDream

In the DeepDream section, you will dive into the fascinating world of creating dream-like images using neural networks. Topics include:
- Understanding the DeepDream algorithm.
- Implementing DeepDream in PyTorch.
- Experimenting with different layers and parameters to create unique visualizations.

## 5. AutoEncoders

This section focuses on AutoEncoders, a type of neural network used for unsupervised learning. You will learn how to:
- Build and train AutoEncoders.
- Use AutoEncoders for dimensionality reduction and image reconstruction.
- Explore variations such as Denoising AutoEncoders and Variational AutoEncoders (VAEs).

## 6. GANs

Generative Adversarial Networks (GANs) are a powerful tool for generating realistic data. In this section, you will:
- Understand the architecture of GANs.
- Implement and train GANs from scratch.
- Experiment with different types of GANs, such as DCGAN and Conditional GANs.

## 7. RNNs and LSTMs

Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks are essential for sequence modeling. This section covers:
- The basics of RNNs and LSTMs.
- Implementing RNNs and LSTMs for tasks like text generation and time series prediction.
- Exploring advanced topics such as bidirectional RNNs and attention mechanisms.

## 8. Vision Transformers

Vision Transformers are a recent advancement in the field of computer vision. In this section, you will:
- Learn the basics of Transformer models.
- Understand how Vision Transformers differ from CNNs.
- Implement and train Vision Transformers for image classification tasks.

## Contributing

If you have suggestions or improvements, feel free to submit a pull request. Contributions are welcome!

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.
